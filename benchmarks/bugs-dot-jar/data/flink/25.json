{
    "bug_id": 25,
    "classification": {
        "singleLine": false
    },
    "commit": "259f10c0",
    "failing_tests": [
        "org.apache.flink.compiler.java.IterationCompilerTest"
    ],
    "files": 3,
    "jira_id": "1167",
    "linesAdd": 7,
    "linesRem": 26,
    "nb_error": 0,
    "nb_failure": 2,
    "nb_skipped": 0,
    "nb_test": 93,
    "patch": "diff --git a/flink-compiler/src/main/java/org/apache/flink/compiler/dag/BulkIterationNode.java b/flink-compiler/src/main/java/org/apache/flink/compiler/dag/BulkIterationNode.java\nindex a5f80268d6..d3f0fbb6fd 100644\n--- a/flink-compiler/src/main/java/org/apache/flink/compiler/dag/BulkIterationNode.java\n+++ b/flink-compiler/src/main/java/org/apache/flink/compiler/dag/BulkIterationNode.java\n@@ -132,7 +132,7 @@ public void setNextPartialSolution(OptimizerNode nextPartialSolution, OptimizerN\n \t\t// check if the root of the step function has the same DOP as the iteration\n \t\t// or if the steo function has any operator at all\n \t\tif (nextPartialSolution.getDegreeOfParallelism() != getDegreeOfParallelism() ||\n-\t\t\tnextPartialSolution == partialSolution)\n+\t\t\tnextPartialSolution == partialSolution || nextPartialSolution instanceof BinaryUnionNode)\n \t\t{\n \t\t\t// add a no-op to the root to express the re-partitioning\n \t\t\tNoOpNode noop = new NoOpNode();\ndiff --git a/flink-compiler/src/main/java/org/apache/flink/compiler/dag/WorksetIterationNode.java b/flink-compiler/src/main/java/org/apache/flink/compiler/dag/WorksetIterationNode.java\nindex 7638cca086..b6ae34e850 100644\n--- a/flink-compiler/src/main/java/org/apache/flink/compiler/dag/WorksetIterationNode.java\n+++ b/flink-compiler/src/main/java/org/apache/flink/compiler/dag/WorksetIterationNode.java\n@@ -160,7 +160,7 @@ public void setNextPartialSolution(OptimizerNode solutionSetDelta, OptimizerNode\n \t\t\n \t\t// there needs to be at least one node in the workset path, so\n \t\t// if the next workset is equal to the workset, we need to inject a no-op node\n-\t\tif (nextWorkset == worksetNode) {\n+\t\tif (nextWorkset == worksetNode || nextWorkset instanceof BinaryUnionNode) {\n \t\t\tNoOpNode noop = new NoOpNode();\n \t\t\tnoop.setDegreeOfParallelism(getDegreeOfParallelism());\n \ndiff --git a/flink-compiler/src/main/java/org/apache/flink/compiler/plandump/PlanJSONDumpGenerator.java b/flink-compiler/src/main/java/org/apache/flink/compiler/plandump/PlanJSONDumpGenerator.java\nindex 00e2bc21e9..60500b81f8 100644\n--- a/flink-compiler/src/main/java/org/apache/flink/compiler/plandump/PlanJSONDumpGenerator.java\n+++ b/flink-compiler/src/main/java/org/apache/flink/compiler/plandump/PlanJSONDumpGenerator.java\n@@ -26,7 +25,6 @@\n import java.io.StringWriter;\n import java.util.ArrayList;\n import java.util.Collection;\n-import java.util.Collections;\n import java.util.HashMap;\n import java.util.Iterator;\n import java.util.List;\n@@ -47,7 +45,6 @@\n import org.apache.flink.compiler.dataproperties.LocalProperties;\n import org.apache.flink.compiler.plan.BulkIterationPlanNode;\n import org.apache.flink.compiler.plan.Channel;\n-import org.apache.flink.compiler.plan.NAryUnionPlanNode;\n import org.apache.flink.compiler.plan.OptimizedPlan;\n import org.apache.flink.compiler.plan.PlanNode;\n import org.apache.flink.compiler.plan.SingleInputPlanNode;\n@@ -265,31 +262,16 @@ private boolean visit(DumpableNode<?> node, PrintWriter writer, boolean first) {\n \t\tif (inConns != null && inConns.hasNext()) {\n \t\t\t// start predecessor list\n \t\t\twriter.print(\",\\n\\t\\t\\\"predecessors\\\": [\");\n-\t\t\tint connNum = 0;\n \t\t\tint inputNum = 0;\n \t\t\t\n \t\t\twhile (inConns.hasNext()) {\n-\t\t\t\tfinal DumpableConnection<?> conn = inConns.next();\n-\t\t\t\t\n-\t\t\t\tfinal Collection<DumpableConnection<?>> inConnsForInput;\n-\t\t\t\tif (conn.getSource() instanceof NAryUnionPlanNode) {\n-\t\t\t\t\tinConnsForInput = new ArrayList<DumpableConnection<?>>();\n-\t\t\t\t\t\n-\t\t\t\t\tfor (DumpableConnection<?> inputOfUnion : conn.getSource().getDumpableInputs()) {\n-\t\t\t\t\t\tinConnsForInput.add(inputOfUnion);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t\telse {\n-\t\t\t\t\tinConnsForInput = Collections.<DumpableConnection<?>>singleton(conn);\n-\t\t\t\t}\n-\t\t\t\t\n-\t\t\t\tfor (DumpableConnection<?> inConn : inConnsForInput) {\n+\t\t\t\tfinal DumpableConnection<?> inConn = inConns.next();\n \t\t\t\tfinal DumpableNode<?> source = inConn.getSource();\n-\t\t\t\t\twriter.print(connNum == 0 ? \"\\n\" : \",\\n\");\n-\t\t\t\t\tif (connNum == 0) {\n+\t\t\t\twriter.print(inputNum == 0 ? \"\\n\" : \",\\n\");\n+\t\t\t\tif (inputNum == 0) {\n \t\t\t\t\tchild1name += child1name.length() > 0 ? \", \" : \"\"; \n \t\t\t\t\tchild1name += source.getOptimizerNode().getPactContract().getName();\n-\t\t\t\t\t} else if (connNum == 1) {\n+\t\t\t\t} else if (inputNum == 1) {\n \t\t\t\t\tchild2name += child2name.length() > 0 ? \", \" : \"\"; \n \t\t\t\t\tchild2name = source.getOptimizerNode().getPactContract().getName();\n \t\t\t\t}\n@@ -331,7 +313,7 @@ private boolean visit(DumpableNode<?> node, PrintWriter writer, boolean first) {\n \t\t\t\t\t\tshipStrategy = \"Rebalance\";\n \t\t\t\t\t\tbreak;\n \t\t\t\t\tdefault:\n-\t\t\t\t\t\t\tthrow new CompilerException(\"Unknown ship strategy '\" + conn.getShipStrategy().name()\n+\t\t\t\t\t\tthrow new CompilerException(\"Unknown ship strategy '\" + inConn.getShipStrategy().name()\n \t\t\t\t\t\t\t+ \"' in JSON generator.\");\n \t\t\t\t\t}\n \t\t\t\t}\n@@ -378,8 +360,6 @@ private boolean visit(DumpableNode<?> node, PrintWriter writer, boolean first) {\n \t\t\t\t}\n \t\t\t\t\n \t\t\t\twriter.print('}');\n-\t\t\t\t\tconnNum++;\n-\t\t\t\t}\n \t\t\t\tinputNum++;\n \t\t\t}\n \t\t\t// finish predecessors\n",
    "project": "flink"
}