{
    "bug_id": 196,
    "classification": {
        "singleLine": false
    },
    "commit": "70564c7c",
    "failing_tests": [
        "org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexTest",
        "org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexQueryTest"
    ],
    "files": 1,
    "jira_id": "1270",
    "linesAdd": 71,
    "linesRem": 17,
    "nb_error": 0,
    "nb_failure": 2,
    "nb_skipped": 1,
    "nb_test": 246,
    "patch": "diff --git a/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java b/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java\nindex 8889094627..0e24834423 100644\n--- a/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java\n+++ b/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java\n@@ -73,10 +73,13 @@\n import org.apache.lucene.index.IndexReader;\n import org.apache.lucene.index.MultiFields;\n import org.apache.lucene.index.Term;\n+import org.apache.lucene.index.Terms;\n+import org.apache.lucene.index.TermsEnum;\n import org.apache.lucene.search.BooleanClause;\n import org.apache.lucene.search.BooleanQuery;\n import org.apache.lucene.search.IndexSearcher;\n import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.MultiPhraseQuery;\n import org.apache.lucene.search.PhraseQuery;\n import org.apache.lucene.search.PrefixQuery;\n import org.apache.lucene.search.Query;\n@@ -87,6 +90,9 @@\n import org.apache.lucene.search.WildcardQuery;\n import org.apache.lucene.store.Directory;\n import org.apache.lucene.store.FSDirectory;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.Automaton;\n+import org.apache.lucene.util.automaton.CompiledAutomaton;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -416,7 +422,7 @@ private static Query getQuery(Filter filter, IndexReader reader,\n             // when using the LowCostLuceneIndexProvider\n             // which is used for testing\n         } else {\n-            qs.add(getFullTextQuery(ft, analyzer));\n+            qs.add(getFullTextQuery(ft, analyzer, reader));\n         }\n         if (nonFullTextConstraints) {\n             addNonFullTextConstraints(qs, filter, reader);\n@@ -582,7 +588,7 @@ private static void addNodeTypeConstraints(List<Query> qs, Filter filter) {\n         qs.add(bq);\n     }\n \n-    static Query getFullTextQuery(FullTextExpression ft, final Analyzer analyzer) {\n+    static Query getFullTextQuery(FullTextExpression ft, final Analyzer analyzer, final IndexReader reader) {\n         // a reference to the query, so it can be set in the visitor\n         // (a \"non-local return\")\n         final AtomicReference<Query> result = new AtomicReference<Query>();\n@@ -592,7 +598,7 @@ static Query getFullTextQuery(FullTextExpression ft, final Analyzer analyzer) {\n             public boolean visit(FullTextOr or) {\n                 BooleanQuery q = new BooleanQuery();\n                 for (FullTextExpression e : or.list) {\n-                    Query x = getFullTextQuery(e, analyzer);\n+                    Query x = getFullTextQuery(e, analyzer, reader);\n                     q.add(x, SHOULD);\n                 }\n                 result.set(q);\n@@ -603,7 +609,7 @@ public boolean visit(FullTextOr or) {\n             public boolean visit(FullTextAnd and) {\n                 BooleanQuery q = new BooleanQuery();\n                 for (FullTextExpression e : and.list) {\n-                    Query x = getFullTextQuery(e, analyzer);\n+                    Query x = getFullTextQuery(e, analyzer, reader);\n                     // Lucene can't deal with \"must(must_not(x))\"\n                     if (x instanceof BooleanQuery) {\n                         BooleanQuery bq = (BooleanQuery) x;\n@@ -625,7 +631,7 @@ public boolean visit(FullTextTerm term) {\n                     // do not add constraints on child nodes properties\n                     p = \"*\";\n                 }\n-                Query q = tokenToQuery(term.getText(), analyzer);\n+                Query q = tokenToQuery(term.getText(), analyzer, reader);\n                 if (q == null) {\n                     return false;\n                 }\n@@ -646,7 +652,7 @@ public boolean visit(FullTextTerm term) {\n         return result.get();\n     }\n \n-    static Query tokenToQuery(String text, Analyzer analyzer) {\n+    static Query tokenToQuery(String text, Analyzer analyzer, IndexReader reader) {\n         if (analyzer == null) {\n             return null;\n         }\n@@ -657,22 +663,27 @@ static Query tokenToQuery(String text, Analyzer analyzer) {\n             // TODO what should be returned in the case there are no tokens?\n             return new BooleanQuery();\n         }\n-\n         if (tokens.size() == 1) {\n-            text = tokens.iterator().next();\n-            boolean hasFulltextToken = false;\n-            for (char c : fulltextTokens) {\n-                if (text.indexOf(c) != -1) {\n-                    hasFulltextToken = true;\n-                    break;\n+            String token = tokens.iterator().next();\n+            if (hasFulltextToken(token)) {\n+                return new WildcardQuery(newFulltextTerm(token));\n+            } else {\n+                return new TermQuery(newFulltextTerm(token));\n             }\n+        } else {\n+            if (hasFulltextToken(tokens)) {\n+                MultiPhraseQuery mpq = new MultiPhraseQuery();\n+                for(String token: tokens){\n+                    if (hasFulltextToken(token)) {\n+                        Term[] terms = extractMatchingTokens(reader, token);\n+                        if (terms != null && terms.length > 0) {\n+                            mpq.add(terms);\n                         }\n-\n-            if (hasFulltextToken) {\n-                return new WildcardQuery(newFulltextTerm(text));\n                     } else {\n-                return new TermQuery(newFulltextTerm(text));\n+                        mpq.add(newFulltextTerm(token));\n                     }\n+                }\n+                return mpq;\n             } else {\n                 PhraseQuery pq = new PhraseQuery();\n                 for (String t : tokens) {\n@@ -681,6 +692,48 @@ static Query tokenToQuery(String text, Analyzer analyzer) {\n                 return pq;\n             }\n         }\n+    }\n+\n+    private static Term[] extractMatchingTokens(IndexReader reader, String token) {\n+        if (reader == null) {\n+            // getPlan call\n+            return null;\n+        }\n+\n+        try {\n+            List<Term> terms = new ArrayList<Term>();\n+            Terms t = MultiFields.getTerms(reader, FieldNames.FULLTEXT);\n+            Automaton a = WildcardQuery.toAutomaton(newFulltextTerm(token));\n+            CompiledAutomaton ca = new CompiledAutomaton(a);\n+            TermsEnum te = ca.getTermsEnum(t);\n+            BytesRef text;\n+            while ((text = te.next()) != null) {\n+                terms.add(newFulltextTerm(text.utf8ToString()));\n+            }\n+            return terms.toArray(new Term[terms.size()]);\n+        } catch (IOException e) {\n+            LOG.error(\"Building fulltext query failed\", e.getMessage());\n+            return null;\n+        }\n+    }\n+\n+    private static boolean hasFulltextToken(List<String> tokens) {\n+        for (String token : tokens) {\n+            if (hasFulltextToken(token)) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private static boolean hasFulltextToken(String token) {\n+        for (char c : fulltextTokens) {\n+            if (token.indexOf(c) != -1) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n \n     private static char[] fulltextTokens = new char[] { '*', '?' };\n \n@@ -727,6 +780,7 @@ static Query tokenToQuery(String text, Analyzer analyzer) {\n                 poz = end;\n                 if (hasFulltextToken) {\n                     token.append(term);\n+                    hasFulltextToken = false;\n                 } else {\n                     if (token.length() > 0) {\n                         tokens.add(token.toString());\n",
    "project": "jackrabbit-oak"
}